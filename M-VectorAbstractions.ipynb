{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morfessor Implementation (Vector Abstractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Outline\n",
    "  - Objective : find constructions\n",
    "      - Compounds = words\n",
    "      - Constructions = morphs\n",
    "      - Atoms = letters/characters\n",
    "  - Components \n",
    "      - Cost Function\n",
    "      - Training\n",
    "      - Decoding\n",
    "  - Model\n",
    "      - Lexicon, Grammar\n",
    "      - Independence assumption vis-a-vis constructions\n",
    "      - MAP estimate - Likelihood + MDL-Prior\n",
    "  - Training Algo\n",
    "      - Greedy & Local Search\n",
    "      - Starts with inital lexicon and tries to find optimal segmentation     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate\n",
    "$argmax_M\\,P(M|corpus)\\,=\\,argmax_M\\,P(corpus|M)\\,P(M)$\n",
    "\n",
    "$P(M)\\,=\\,P(lexicon,grammar)=\\,P(lexicon)$ (for baseline)\n",
    "\n",
    "### Prior Probability - MDL Formulation\n",
    "Supposing that there are $L$ different morphs,\n",
    "\n",
    "$P(lexicon)\\,=\\,L!\\,P(properties(\\mu_1)...properties(\\mu_L))$\n",
    "\n",
    "$L!$ ways to order the list, properties - frequency, string of letters\n",
    "\n",
    "\n",
    "$P(properties(\\mu_1)...properties(\\mu_L))\\,=\\,P(f_{\\mu_1},..f_{\\mu_L}).P(s_{\\mu_1},..s_{\\mu_L})$\n",
    "\n",
    "$P(f_{\\mu_1},..f_{\\mu_L})\\,=\\,\\frac{(L-1)!(N-L)!}{(N-1)!}$ - Implicit frequency modeling - Appendix A\n",
    "\n",
    "where $N=\\Sigma_{j=1}^{L} f_{\\mu_j}$ Total number of morph tokens\n",
    "\n",
    "$P(s_{\\mu_1},..s_{\\mu_L})\\,=\\,\\Pi_{i=1}^{L} P(s_{\\mu_i})\\,=\\,\\Pi_{i=1}^{L} \\Pi_{j=1}^{l_{\\mu_i}} P(c_{ij})$ - Probability of each character multiplied - Implicit modeling of length with '#' marker added to each morph at the end\n",
    "\n",
    "### Likelihood - MLE Formulation\n",
    "$P(corpus|M)\\,=\\,\\Pi_{j=1}^{W}\\Pi_{k=1}^{n_j}P(\\mu_{jk})$ - There are $W$ words, each word split into $n_j$ morphs\n",
    "\n",
    "$P(\\mu_i)\\,=\\,\\frac{f_{\\mu_i}}{N}\\,=\\,\\frac{f_{\\mu_i}}{\\Sigma_{j=1}^{L} f_{\\mu_j}}$\n",
    "\n",
    "### Putting it all together\n",
    "$argmax_M\\,P(M|corpus)\\,=\\,argmax_M\\,P(corpus|M)\\,P(M)$\n",
    "\n",
    "\n",
    "$argmax_M\\,P(M|corpus)\\,=\\,argmax_M\\,\\Pi_{j=1}^{W}\\Pi_{k=1}^{n_j}P(\\mu_{jk})\\,.\\,L!\\frac{(L-1)!(N-L)!}{(N-1)!}.\\Pi_{i=1}^{L} \\Pi_{j=1}^{l_{\\mu_i}} P(c_{ij})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymagnitude import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/wikitext-2/train.txt'\n",
    "#mag_file  = 'vectors/wiki_train_words/wiki_train_words.magnitude'\n",
    "mag_file = '../tools/GloVe/ukwac-10L.magnitude'\n",
    "#mag_file = '../tools/GloVe/tel_tok.magnitude'\n",
    "#data_file = 'test_corpus.txt'\n",
    "#data_file = 'data/tel/train.txt.tok.tok'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "vectors = Magnitude(mag_file)\n",
    "VECDIM = vectors.dim\n",
    "VECCOST = math.log(VECDIM)\n",
    "print(VECDIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, form, count=0, cxn = False):\n",
    "        self.form = form\n",
    "        self.count = count\n",
    "        self.slotvectors = {}\n",
    "        self.slots = Counter()\n",
    "        self.cxn = cxn\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        if type(self.form) == str:\n",
    "            form = f\"{self.form}/{self.count}\"    \n",
    "        else:\n",
    "            comps = []\n",
    "            for slot_pos in range(len(self.form)):\n",
    "                if slot_pos not in self.slots:\n",
    "                    f = self.form[slot_pos]\n",
    "                else:\n",
    "                    neibs = [x[0] for x in sorted(self.slots[slot_pos].items(), key = lambda x: x[1], reverse=True)[:3]]\n",
    "                    f = '['+'/'.join(neibs)+']'\n",
    "                comps.append(f)\n",
    "            comps = '_'.join(comps)\n",
    "            form = f\"{comps}/{self.count}\"\n",
    "        return f\"({form})\"\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "charmap = {}\n",
    "num_tokens = 0\n",
    "import re \n",
    "by_space = re.compile('\\s+')\n",
    "with open(data_file, errors='ignore') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if len(line) > 0:\n",
    "            #line = line.replace(\"#\", '')\n",
    "            line = by_space.split(line)\n",
    "                       \n",
    "            for tok in line:\n",
    "                if tok not in nodes:\n",
    "                    nodes[tok] = Node(tok)\n",
    "                for c in tok:\n",
    "                    if c not in charmap:\n",
    "                        charmap[c] = 0\n",
    "                    charmap[c] += 1\n",
    "                nodes[tok].count += 1\n",
    "                num_tokens += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def print_nodes(nodes):\n",
    "    for tok, node in nodes.items():\n",
    "        print(node)\n",
    "        \n",
    "def counts_to_logprobs(counts):\n",
    "    total_count = sum(counts.values())\n",
    "    logprobs = {}\n",
    "    for key, value in counts.items():\n",
    "        logprobs[key] = -math.log(value/total_count)\n",
    "    return logprobs\n",
    "\n",
    "\n",
    "def stirlings_approximation(n):\n",
    "    return n * math.log(n) - n + 0.5*(math.log(n) + math.log(2*math.pi))\n",
    "\n",
    "def log_fact(n):\n",
    "    if n < 2:\n",
    "        return 0\n",
    "    if n < 20:\n",
    "        return math.log(math.factorial(n))\n",
    "    return stirlings_approximation(n)\n",
    "\n",
    "def implicit_frequency(num_types, num_tokens):\n",
    "    \"\"\"\n",
    "        P(F) = ((L-1)! x (N-L) !) / (N-1) !\n",
    "        C(F) = -(log((L-1)!) + log((N-L)!) - log((N-1)!))\n",
    "    \"\"\" \n",
    "    return log_fact(num_tokens - 1) - log_fact(num_tokens - num_types) - log_fact(num_types -1)\n",
    "\n",
    "\n",
    "# Currently not adding '#' character at the end. Need to add that and see how it works out.\n",
    "def implicit_length_cost(types, charmap):\n",
    "    \"\"\"\n",
    "        C(S) = Sigma_i_|words| ( Sigma_j_|wi| (-log(P(c_ij))) )\n",
    "    \"\"\"\n",
    "    total_cost = 0\n",
    "    for t in types:\n",
    "        for char in t:\n",
    "            total_cost += charmap[char]\n",
    "    return total_cost\n",
    "\n",
    "def lexicon_cost(num_tokens, nodes, charmap):\n",
    "    \n",
    "    return  implicit_frequency(len(nodes), num_tokens) + implicit_length_cost(nodes, charmap) -  log_fact(len(nodes))\n",
    "\n",
    "\n",
    "def corpus_cost(node_probs):\n",
    "    total_cost = 0\n",
    "    with open(data_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                line = by_space.split(line)\n",
    "                for tok in line:\n",
    "                    total_cost += node_probs[tok]\n",
    "    return total_cost\n",
    "\n",
    "def corpus_cost_eff(nodes, num_tokens):\n",
    "    \"\"\"\n",
    "        compute Sigma_i_L(f(i) * log(f(i))) - NlogN\n",
    "    \"\"\"\n",
    "    \n",
    "    node_counts = {k : v.count*math.log(v.count) for k, v in nodes.items()}\n",
    "    return -(sum(node_counts.values()) - num_tokens * math.log(num_tokens))\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy\n",
    "def distance(x, y, yvector = False):\n",
    "    if not yvector:\n",
    "        d = 1-cosine(vectors.query(x), vectors.query(y))\n",
    "    else:\n",
    "        d = 1-cosine(vectors.query(x), y)\n",
    "    if d <= 0:\n",
    "        return numpy.inf\n",
    "    return -math.log(d)\n",
    "\n",
    "from fastdist import fastdist\n",
    "def fdistance(x, y):\n",
    "    if type(x) == str:\n",
    "        x = vectors.query(x)\n",
    "    if type(y) == str:\n",
    "        y = vectors.query(y)\n",
    "    d = fastdist.cosine(x, y)\n",
    "    if d <= 0:\n",
    "        return numpy.inf\n",
    "    return -math.log(d)\n",
    "\n",
    "\n",
    "def fdistance_pw(x, y):\n",
    "    if type(x) == str:\n",
    "        x = vectors.query(x)\n",
    "    if type(y) == str:\n",
    "        y = {y : 1}\n",
    "        \n",
    "    y_vectors = [c * vectors.query(z) for z, c in y.items()]\n",
    "    try:\n",
    "        mv = numpy.mean(y_vectors, axis=0)\n",
    "    except:\n",
    "        print(x,y)\n",
    "    ds = []\n",
    "    y_vectors.append(x)\n",
    "    ds = [fastdist.cosine(p, mv) for p in y_vectors]\n",
    "   \n",
    "    D = sum(ds)\n",
    "    d = ds[-1] / D\n",
    "    #print(ds, D)\n",
    "#     d = 0\n",
    "#     for z in y:\n",
    "#         if type(z) == str:\n",
    "#             z = vectors.query(z)\n",
    "        \n",
    "#         d += fastdist.cosine(x, z)\n",
    "        \n",
    "#     d = d / len(y)\n",
    "    if d <= 0:\n",
    "        return numpy.inf\n",
    "    return -math.log(d)\n",
    "\n",
    "\n",
    "def normalize(word_vec):\n",
    "    norm=numpy.linalg.norm(word_vec)\n",
    "    if norm == 0: \n",
    "        return word_vec\n",
    "    return word_vec/norm\n",
    "\n",
    "# def get_top_n_keys(d, n=5):\n",
    "#     return {x[0] : x[1] for x in sorted(d.items(), key=lambda x : x[1], reverse=True)[:n]}\n",
    "\n",
    "def get_top_n_keys(d, n=5):\n",
    "    return {x[0] : x[1] for x in d.most_common()[:n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_types = len(nodes.keys())\n",
    "charmap_logs = counts_to_logprobs(charmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170151.9303001716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14566281.632556107"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(implicit_frequency(num_types, num_tokens))\n",
    "corpus_cost_eff(nodes, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Rules\n",
    "\n",
    "### Removing a node t\n",
    "\n",
    "1. Frequency Cost:\n",
    " * Number of types decreases by 1.    \n",
    "    $L' = L - 1$      \n",
    " * Number of tokens decreases by f(t).   \n",
    "    $N' = N - f(t)$        \n",
    " * $C(F)' = -(log((L'-1)!) + log((N'-L')!) - log((N'-1)!))$\n",
    "  \n",
    "  \n",
    "2. Length Cost:\n",
    "  * $C(S)' = C(S) - \\Sigma_{i}^{|t|} -log(p(ci)$\n",
    "  \n",
    "  \n",
    "3. Corpus cost:\n",
    "  * Number of tokens decreases by f(t).   \n",
    "     $N' = N - f(t)$        \n",
    "  * A decrease in the total count by f(t)\n",
    "  * $C(corpus)  = NlogN - \\Sigma_i^L (f(i) * log(f(i)))$\n",
    "  * $C(corpus)' = C(corpus) + f(t)*log(f(t)) - NlogN + N'logN'$\n",
    "\n",
    "### Adding a node t with parent u\n",
    "\n",
    "1. Frequency Cost:\n",
    " * If t is new, Number of types increases by 1.    \n",
    "    $L' = L + 1$      \n",
    " * Number of tokens increases by f(u).   \n",
    "    $N' = N + f(u)$        \n",
    " * $C(F)' = -(log((L'-1)!) + log((N'-L')!) - log((N'-1)!))$\n",
    "  \n",
    "  \n",
    "2. Length Cost (if t is new):\n",
    "  * $C(S)' = C(S) + \\Sigma_{i}^{|t|} -log(p(ci)$\n",
    "  \n",
    "  \n",
    "3. Corpus cost:\n",
    "  * Number of tokens increases by f(u).   \n",
    "     $N' = N - f(u)$        \n",
    "  * An increase in the total count by f(u)\n",
    "  * $C(corpus)  = NlogN - \\Sigma_i^L (f(i) * log(f(i)))$\n",
    "  * $C(corpus)' = C(corpus) - f(u)*log(f(u)) - NlogN + N'logN'$\n",
    "  \n",
    "   \n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorfessorModel:\n",
    "    def __init__(self, charmap_logs):\n",
    "        self.frequency_cost = 0\n",
    "        self.length_cost = 0\n",
    "        self.corpus_cost = 0\n",
    "        self.total_cost = 0\n",
    "        \n",
    "        self.num_types = 0\n",
    "        self.num_tokens = 0\n",
    "        \n",
    "        self.charmap_logs = charmap_logs\n",
    "        \n",
    "        self.nodes = {}\n",
    "        self.cxns = {}\n",
    "        \n",
    "   \n",
    "        \n",
    "    def add_node(self, token, count, parent=None, debug=False):\n",
    "        num_types_new = self.num_types\n",
    "        old_count = 0\n",
    "        node_count = count\n",
    "        if debug:\n",
    "            print(\"A Cost Before\", self.corpus_cost, self.frequency_cost, self.length_cost)\n",
    "\n",
    "        \n",
    "        if token not in self.nodes:\n",
    "            self.num_types = self.num_types + 1\n",
    "            self.length_cost = self.length_cost + sum([self.charmap_logs[char] for char in token if char not in ['_','[',']']])\n",
    "            if '_' in token:\n",
    "                split_tok = token.split('_')\n",
    "                self.nodes[token] = Node(split_tok, count, cxn = True)    \n",
    "                head, tail = '_'.join(split_tok[:-1])+'_', '_' + split_tok[-1]\n",
    "                if head not in self.cxns:\n",
    "                    self.cxns[head] = {}\n",
    "                self.cxns[head][tail] = self.nodes[token]\n",
    "                if tail not in self.cxns:\n",
    "                    self.cxns[tail] = {}\n",
    "                self.cxns[tail][head] = self.nodes[token]\n",
    "                \n",
    "            else:\n",
    "                self.nodes[token] = Node(token, count)\n",
    "        \n",
    "        else:\n",
    "            if self.nodes[token].count == 0:\n",
    "                self.num_types += 1\n",
    "\n",
    "            else:\n",
    "                count += self.nodes[token].count # Update the count            \n",
    "                old_count = self.nodes[token].count * math.log(self.nodes[token].count)\n",
    "\n",
    "\n",
    "            self.nodes[token].count = count\n",
    "\n",
    "               \n",
    "        num_tokens_new = self.num_tokens + node_count\n",
    "        \n",
    "        \n",
    "        self.frequency_cost = implicit_frequency(self.num_types, num_tokens_new)    \n",
    "        \n",
    "        if debug:\n",
    "            print(\"A components \", old_count, - count * math.log(count), \"delta : \", old_count - count * math.log(count), - ((self.num_tokens * math.log(self.num_tokens)) if self.num_tokens > 0 else 0), (num_tokens_new * math.log(num_tokens_new))  )\n",
    "\n",
    "        self.corpus_cost = self.corpus_cost + old_count \\\n",
    "                                            - count * math.log(count) \\\n",
    "                                            - ((self.num_tokens * math.log(self.num_tokens)) if self.num_tokens > 0 else 0) \\\n",
    "                                            + (num_tokens_new * math.log(num_tokens_new))\n",
    "        \n",
    "        if debug:\n",
    "            print(\"A Cost After\", self.corpus_cost, self.frequency_cost, self.length_cost)\n",
    "\n",
    "        self.num_tokens = num_tokens_new\n",
    "        self.total_cost = self.corpus_cost + self.frequency_cost + self.length_cost\n",
    "        \n",
    "        \n",
    "    def remove_node(self, token, decrease_by, debug = False):\n",
    "        node = self.nodes[token]\n",
    "        count = node.count - decrease_by\n",
    "        \n",
    "        if debug:\n",
    "            print(\"R Cost Before\", self.corpus_cost, self.frequency_cost, self.length_cost)\n",
    "\n",
    "        \n",
    "        if count == 0:\n",
    "            self.num_types = self.num_types - 1\n",
    "            self.length_cost = self.length_cost - sum([self.charmap_logs[char] for char in token if char not in ['_','[',']']])\n",
    "            \n",
    "        num_tokens_new = self.num_tokens - decrease_by\n",
    "    \n",
    "        self.frequency_cost = implicit_frequency(self.num_types, num_tokens_new)               \n",
    "        \n",
    "        self.corpus_cost = self.corpus_cost + node.count * math.log(node.count) \\\n",
    "                                            - (count * math.log(count) if count > 0 else 0) \\\n",
    "                                            - (self.num_tokens * math.log(self.num_tokens)) \\\n",
    "                                            + (num_tokens_new * math.log(num_tokens_new))\n",
    "        \n",
    "        if debug:\n",
    "            print(\"R Cost After\", self.corpus_cost, self.frequency_cost, self.length_cost)\n",
    "\n",
    "        \n",
    "        self.total_cost = self.corpus_cost + self.frequency_cost + self.length_cost\n",
    "        self.num_tokens = num_tokens_new\n",
    "        \n",
    "        self.nodes[token].count -= decrease_by\n",
    "        \n",
    "        if self.nodes[token].count <= 0:\n",
    "            del self.nodes[token]\n",
    "            if '_' in token:\n",
    "                split_tok = token.split('_')\n",
    "                head, tail = '_'.join(split_tok[:-1])+'_', '_' + split_tok[-1]\n",
    "                if head in self.cxns:\n",
    "                    del self.cxns[head][tail]\n",
    "\n",
    "                if len(self.cxns[head]) == 0:\n",
    "                    del self.cxns[head]\n",
    "\n",
    "                if tail in self.cxns:\n",
    "                    del self.cxns[tail][head]\n",
    "\n",
    "                if len(self.cxns[tail]) == 0:\n",
    "                    del self.cxns[tail]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorfessorModel(charmap_logs)\n",
    "import random\n",
    "tokens = [(k,v.count) for k, v in nodes.items()]\n",
    "#random.shuffle(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33277/33277 [00:00<00:00, 51868.07it/s] \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "m.originals = {}\n",
    "for token, count in tqdm.tqdm(tokens):\n",
    "    m.add_node(token, count)\n",
    "    m.originals[token] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051910, 15516165.546927406, 33277)"
      ]
     },
     "execution_count": 1454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.num_tokens, m.total_cost, m.num_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def should_join(prev, tok, debug=False):\n",
    "        candidate = prev+'_'+tok\n",
    "        new_candidate = False\n",
    "        # Current cost\n",
    "        old_cost = m.total_cost\n",
    "        cand_count = 0\n",
    "        if candidate in m.nodes:\n",
    "            cand_count = 1\n",
    "        if cand_count == 0 and (candidate in m.originals):\n",
    "            cand_count = m.originals[candidate] + 1\n",
    "        elif cand_count == 0:\n",
    "            cand_count = 1\n",
    "\n",
    "        m.remove_node(prev, cand_count, debug=debug)\n",
    "        \n",
    "        if tok not in m.nodes:\n",
    "            m.add_node(prev, cand_count, debug=debug)\n",
    "            # No splitting\n",
    "            return None, None\n",
    "        \n",
    "        m.remove_node(tok, cand_count, debug=debug)\n",
    "            \n",
    "        m.add_node(candidate, cand_count, debug = debug)\n",
    "        # Retain the node if the cost is lower                       \n",
    "        if m.total_cost < old_cost:\n",
    "             return True, cand_count\n",
    "        return False, cand_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_once(data_file, debug):\n",
    "    new_candidate = False\n",
    "    with open(data_file, errors='ignore') as f:\n",
    "        for i, line in tqdm.tqdm(enumerate(f)):\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                #line = line.replace(\"#\", '')\n",
    "                line = by_space.split(line)\n",
    "                #line = \"#\".join(line)\n",
    "                prev = line[0]\n",
    "                \n",
    "                for tok in line[1:]:\n",
    "                    candidate = prev+'_'+tok\n",
    "                    new_candidate = False\n",
    "                    \n",
    "                    if prev not in m.nodes:\n",
    "                        prev = candidate\n",
    "                    elif tok in m.nodes:\n",
    "                        \n",
    "                        best_prev = tok, m.total_cost, 'I'\n",
    "                        best_match = [None, None]\n",
    "                        \n",
    "                        # Word_Word compound.\n",
    "                        sj, cand_count = should_join(prev, tok, debug=debug)\n",
    "                        \n",
    "                        \n",
    "                        revert_prev_tok = not sj if sj != None else False\n",
    "                        if sj == True:\n",
    "                            #print()\n",
    "                            best_prev = candidate, m.total_cost, 'T_T'\n",
    "                        \n",
    "                        \n",
    "                        # First remove the candidate to search for matches\n",
    "                        # This does not depend on whether the candidate is to be joined or not.\n",
    "                        # After this point, we would have removed prev, tok and candidate. Ideal for finding the match.\n",
    "                        if sj != None:\n",
    "                            m.remove_node(candidate, cand_count, debug=debug)\n",
    "                        \n",
    "                        # Lets search all the cxns that start with prev.\n",
    "                        # The construction can be filled only if the slot we are dealing with is terminal.\n",
    "                        # That is why cannot have continuation (\"_\") after the current token.\n",
    "                        \n",
    "                        head, tail = prev + '_', '_' + tok\n",
    "                        \n",
    "                        # Check for X_C(Y) first.\n",
    "                        if head in m.cxns:\n",
    "                            matched = m.cxns[head]\n",
    "                            #print(matched)\n",
    "                            \n",
    "                            most_similar = (None, numpy.inf)\n",
    "                            \n",
    "                            for ctail, mat in matched.items():\n",
    "                                #print(ctail, mat)\n",
    "                                # Check if match already has a slot \n",
    "                                slot_pos = (len(mat.form) - 1)\n",
    "                                if slot_pos in mat.slots:\n",
    "                                    #likely_similar = list(mat.slots[slot_pos].keys())\n",
    "                                    likely_similar = get_top_n_keys(mat.slots[slot_pos])\n",
    "                                else:\n",
    "                                    likely_similar = mat.form[-1]\n",
    "                                    if likely_similar == tok: # No point in merging the same things\n",
    "                                        continue \n",
    "                                        \n",
    "                                similarity = fdistance_pw(tok, likely_similar)\n",
    "                                if similarity < most_similar[1]:\n",
    "                                    most_similar = (mat, similarity)\n",
    "                                    \n",
    "                            if most_similar[0]:\n",
    "                                #print(prev, tok, most_similar, best_prev, sj, m.total_cost)\n",
    "                                mat = most_similar[0]\n",
    "                                old_mat = copy.deepcopy(mat)\n",
    "                                old_cand = None\n",
    "                                slot_pos = (len(mat.form) - 1)\n",
    "                                merge_cost = 0\n",
    "                                slot_cost = 0\n",
    "                                merged = [False, False]\n",
    "                                # If we are creating a new construction\n",
    "                                if slot_pos not in mat.slots:\n",
    "                                    cxn_id = len(matched) + 1 \n",
    "                                    cxn_candidate = prev + '_' + f'[Q{cxn_id}]'\n",
    "                                    cxn_candidate_count = mat.count + 1       \n",
    "                                    #tgt_vector = vectors.query(mat.form[-1])         \n",
    "                                    # As we are merging the two constructions, let us remove the old\n",
    "                                    if '_'.join(mat.form) in m.nodes:\n",
    "                                        m.remove_node('_'.join(mat.form), mat.count, debug=debug)\n",
    "                                        merged[0] = True\n",
    "                                    if candidate in m.nodes:\n",
    "                                        old_cand = copy.deepcopy(m.nodes[candidate])\n",
    "                                        m.remove_node(candidate, m.nodes[candidate].count, debug=debug)\n",
    "                                        merged[1] = True\n",
    "                                    slot_cost = math.log(sys.getsizeof(str(tok+mat.form[-1])))\n",
    "                                    \n",
    "                                else:\n",
    "                                    # Construction already exists. Need to update the count and avg vector\n",
    "                                    cxn_candidate = '_'.join(mat.form)\n",
    "                                    cxn_candidate_count = 1  \n",
    "                                    cxn_node = m.nodes[cxn_candidate]\n",
    "                                    if tok not in mat.slots[slot_pos]:\n",
    "                                        slot_cost += math.log(sys.getsizeof(tok))\n",
    "                                    #tgt_vector = cxn_node.slotvectors[slot_pos]\n",
    "                        \n",
    "                                m.add_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                                \n",
    "                                cxn_cost = m.total_cost + most_similar[1] + slot_cost\n",
    "                                if cxn_cost >= best_prev[1]:\n",
    "                                    #print(\"Not making a construction now.\")\n",
    "                                    \n",
    "                                    m.remove_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                                    if merged[0]:\n",
    "                                        m.add_node('_'.join(old_mat.form), old_mat.count, debug=debug)                                        \n",
    "                                    if merged[1]:\n",
    "                                        m.add_node('_'.join(old_cand.form), old_cand.count, debug=debug)                                        \n",
    "                                        \n",
    "                                    \n",
    "                                else:\n",
    "                                    #print(\"Updating the CxN\", prev, tok, cxn_candidate, mat, mat.form[-1], cxn_cost, sj)\n",
    "                                    best_match = mat, cxn_candidate_count\n",
    "                                    best_prev = cxn_candidate, cxn_cost, 'T_C'                                    \n",
    "                                    revert_prev_tok = False\n",
    "                            \n",
    "                        if best_prev[-1] == 'T_C':\n",
    "                            m.remove_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                            \n",
    "                        # Lets check for C(X)_Y        \n",
    "                        if tail in m.cxns and prev.count('_') == 0:\n",
    "                            matched = m.cxns[tail]\n",
    "                            #print(matched)\n",
    "                            \n",
    "                            most_similar = (None, numpy.inf)\n",
    "                            \n",
    "                            prev_vector = numpy.zeros(VECDIM)\n",
    "                            if prev in m.nodes:\n",
    "                                prev_node = m.nodes[prev]\n",
    "                            else:\n",
    "                                prev_node = Node(prev, count=1)\n",
    "                                    \n",
    "                            for slot_pos in range(len(prev_node.form)):\n",
    "                                if slot_pos in prev_node.slots:\n",
    "                                    prev_vector += numpy.mean(list(prev_node.slots[slot_pos].keys()), axis=0)\n",
    "                                else:\n",
    "                                    prev_vector += vectors.query(prev_node.form[slot_pos])\n",
    "                            \n",
    "                            prev_vector = normalize(prev_vector)\n",
    "                            slot_pos = 0\n",
    "                            for chead, mat in matched.items():\n",
    "                                #print(ctail, mat)\n",
    "                                # Check if match already has a slot \n",
    "                                \n",
    "                                if chead != head:\n",
    "                                    likely_similar = numpy.zeros(VECDIM)\n",
    "                                    if len(mat.form) == 2:\n",
    "#                                         for slot_pos in range(len(mat.form) - 1):\n",
    "#                                             if slot_pos in mat.slots:\n",
    "#                                                 likely_similar += mat.slotvectors[slot_pos]                                    \n",
    "#                                             else:\n",
    "#                                                 likely_similar += vectors.query(mat.form[slot_pos])\n",
    "                                        if slot_pos in mat.slots:\n",
    "                                            #likely_similar = list(mat.slots[slot_pos].keys())\n",
    "                                            likely_similar = get_top_n_keys(mat.slots[slot_pos])\n",
    "                                        else:\n",
    "                                            likely_similar = mat.form[slot_pos]\n",
    "\n",
    "\n",
    "                                        similarity = fdistance_pw(prev_vector, likely_similar)\n",
    "                                        if similarity < most_similar[1]:\n",
    "                                            most_similar = (mat, similarity)\n",
    "\n",
    "                            if most_similar[0]:\n",
    "                                #print(prev_node, tok, most_similar, best_prev, sj, m.total_cost)\n",
    "                                mat = most_similar[0]\n",
    "                                old_mat = copy.deepcopy(mat)\n",
    "                                old_cand = None\n",
    "                                merged = [False, False]\n",
    "                                slot_pos = 0                                \n",
    "                                slot_cost = 0\n",
    "                                if (len(mat.form) == 2) and (slot_pos in mat.slots):\n",
    "                                    # Something line [Q]_Y exists\n",
    "                                    cxn_candidate = '_'.join(mat.form)\n",
    "                                    cxn_candidate_count = 1  \n",
    "                                    cxn_node = m.nodes[cxn_candidate]\n",
    "                                    \n",
    "                                    if prev not in mat.slots[slot_pos]:\n",
    "                                        slot_cost += math.log(sys.getsizeof(prev))\n",
    "                                    #tgt_vector = cxn_node.slotvectors[slot_pos]\n",
    "                                    \n",
    "                                else:\n",
    "                                    cxn_id = len(matched) + 1 \n",
    "                                    cxn_candidate = f'[Q{cxn_id}]' + \"_\" + tok\n",
    "                                    cxn_candidate_count = mat.count + 1      \n",
    "                                    slot_cost = math.log(sys.getsizeof(str(prev+mat.form[0])))\n",
    "                                    \n",
    "\n",
    "                                    # As we are merging the two constructions, let us remove the old\n",
    "                                    if '_'.join(mat.form) in m.nodes:\n",
    "                                        m.remove_node('_'.join(mat.form), mat.count, debug=debug)\n",
    "                                        merged[0] = True\n",
    "                                    \n",
    "                                                                            \n",
    "                                                                                                                                       \n",
    "                                if candidate in m.nodes:\n",
    "                                    old_cand = copy.deepcopy(m.nodes[candidate])\n",
    "                                    m.remove_node(candidate, m.nodes[candidate].count, debug=debug)\n",
    "                                    merged[1] = True\n",
    "                                    \n",
    "                                m.add_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                                cxn_cost = m.total_cost + most_similar[1] + slot_cost\n",
    "                                if cxn_cost >= best_prev[1]:\n",
    "                                    #print(\"Not making a construction now.\")\n",
    "                                    \n",
    "                                    m.remove_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                                    if merged[0]:\n",
    "                                        m.add_node('_'.join(old_mat.form), old_mat.count, debug=debug)                                        \n",
    "                                    if merged[1]:\n",
    "                                        m.add_node('_'.join(old_cand.form), old_cand.count, debug=debug)       \n",
    "                                    \n",
    "                                else:\n",
    "                                    #print(\"Updating the CxN\", prev, tok, cxn_candidate, mat, mat.form[-1], cxn_cost, sj)\n",
    "                                    cxn_node = m.nodes[cxn_candidate]\n",
    "                                    best_match = mat, cxn_candidate_count\n",
    "                                \n",
    "                                    if tok in m.nodes:\n",
    "                                        for spos, sloti in m.nodes[tok].slots.items():\n",
    "                                            if spos not in cxn_node.slots:\n",
    "                                                cxn_node.slots[spos] = Counter()\n",
    "                                            cxn_node.slots[spos].update(sloti)\n",
    "                                             \n",
    "                                    # Update the avg vector\n",
    "                                    #print(f\"I am merging {mat} with {candidate} best_prev : {best_prev} similarity : {most_similar[1]}\")\n",
    "                                    if slot_pos not in cxn_node.slots:\n",
    "                                        cxn_node.slots[slot_pos] = Counter({mat.form[0]:1})\n",
    "                                    if prev not in cxn_node.slots[slot_pos]:\n",
    "                                        cxn_node.slots[slot_pos][prev] = 0\n",
    "                                    cxn_node.slots[slot_pos][prev] += 1\n",
    "                                        \n",
    "                                    #cxn_node.slots[slot_pos] = normalize(tgt_vector +  prev_vector)\n",
    "                                    #xn_node.slotvectors[slot_pos] = numpy.mean([tgt_vector,prev_vector], axis=0)\n",
    "                                   # print(f\"Results {cxn_node}\")\n",
    "                                    best_prev = cxn_candidate, cxn_cost, 'C_T'\n",
    "                                    revert_prev_tok = False\n",
    "                                    \n",
    "                        # Because we removed the candidate, add it back.\n",
    "                        if best_prev[-1] == 'T_C':\n",
    "                            \n",
    "                            cxn_candidate =  best_prev[0]\n",
    "                            cxn_candidate_count = best_match[1]\n",
    "                            #print(best_prev)\n",
    "                            m.add_node(cxn_candidate, cxn_candidate_count, debug=debug)\n",
    "                            \n",
    "                            cxn_node = m.nodes[cxn_candidate]\n",
    "                            \n",
    "                            if prev in m.nodes:\n",
    "                                for spos, sloti in m.nodes[prev].slots.items():\n",
    "                                    if spos not in cxn_node.slots:\n",
    "                                        cxn_node.slots[spos] = Counter()\n",
    "                                    cxn_node.slots[spos].update(sloti)\n",
    "                                             \n",
    "                            \n",
    "                            \n",
    "                            slot_pos = len(best_match[0].form)  - 1\n",
    "                            if slot_pos not in cxn_node.slots:\n",
    "                                cxn_node.slots[slot_pos] = Counter({best_match[0].form[-1]:1})\n",
    "                                            \n",
    "                            if tok not in cxn_node.slots[slot_pos]:\n",
    "                                cxn_node.slots[slot_pos][tok] = 0\n",
    "                                        \n",
    "                            cxn_node.slots[slot_pos][tok] += 1\n",
    "                                    \n",
    "                            \n",
    "                            \n",
    "                        elif best_prev[2] == 'T_T':\n",
    "                            m.add_node(candidate, cand_count, debug = debug)\n",
    "                            \n",
    "                        if revert_prev_tok == True:\n",
    "                              # Revert back !\n",
    "                            #m.remove_node(candidate, cand_count, debug=debug)\n",
    "                            \n",
    "                            m.add_node(prev, cand_count, debug=debug)\n",
    "                            m.add_node(tok, cand_count, debug=debug)\n",
    "                            \n",
    "                        prev = best_prev[0]\n",
    "#                             prev = tok\n",
    "                                                                         \n",
    "\n",
    "                        \n",
    "                        \n",
    "                    if candidate not in m.originals:\n",
    "                        m.originals[candidate] = 0\n",
    "                    m.originals[candidate] += 1\n",
    "#             if i > 50:\n",
    "#                  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36718it [02:05, 292.78it/s]\n"
     ]
    }
   ],
   "source": [
    "run_once(data_file, debug=False)\n",
    "# # Reset Originals\n",
    "# m.originals = {}\n",
    "# for k, v in m.nodes.items():\n",
    "#     m.originals[k] = v.count\n",
    "\n",
    "\n",
    "# %time print(distance('this', 'the'))\n",
    "# %time print(fdistance('this', 'the'))\n",
    "\n",
    "#%prun normalize(a + b)\n",
    "#%time normalize(a + b)\n",
    "#%time numpy.mean([a, b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720655, 7687279.370708236, 34503)"
      ]
     },
     "execution_count": 1457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.num_tokens, m.total_cost, m.num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(_[Q2]_[Q2]_[Q2]', ((_[died/now/or]_[–///mi]_[)/or/long]/233)),\n",
       " ('[Q2]_to_[Q2]_[Q2]', ([back/began/Ode]_to_[have/do/an]_[to/on/their]/191)),\n",
       " ('[Q2]_(_[Q2]_[Q2]_[Q2]', ([-/miles/feet]_(_[)/5/9]_[//)/;]_[;/long/at]/129)),\n",
       " ('[Q2]_that_[Q2]_[Q2]',\n",
       "  ([stated/noted/said]_that_[it/he/was]_[was/had/to]/127)),\n",
       " ('[Q5]_(_[Q2]_[Q2]', ([acres/6/long]_(_[10/100/PHP]_[//ISBN/:]/76)),\n",
       " ('[Q3]_@-@_[Q2]_[Q2]',\n",
       "  ([All/all/three]_@-@_[inch/day/gun]_[line/@-@/fire]/75)),\n",
       " ('[Q2]_were_[Q2]_[Q2]',\n",
       "  ([they/They/guns]_were_[made/also/created]_[over/:/by]/67)),\n",
       " ('[Q2]_a_[Q2]_[Q2]', ([in/,/as]_a_[gold/result/god]_[of/@-@/present]/59)),\n",
       " ('[Q2]_\"_[Q2]_[Q2]', ([./was/that]_\"_[A./\"/was]_[\"/also/that]/46)),\n",
       " ('[Q2]_was_[Q2]_[Q2]',\n",
       "  ([it/that/she]_was_[to/later/released]_[to/by/was]/41)),\n",
       " ('[Q2]_@.@_[Q2]_[Q2]', ([1/2/5]_@.@_[2/0/5]_[%/in/Rowson]/33)),\n",
       " ('[Q2]_)_–_@-@', ([Q2]_)_–_@-@/24)),\n",
       " (\"[Q2]_'_[Q2]_'\", ([Q2]_'_[Q2]_'/17)),\n",
       " ('[Q2]_Light_Horse_Brigade', ([Q2]_Light_Horse_Brigade/16)),\n",
       " ('[Q2]_in_[Q2]_[Q2]',\n",
       "  ([used/interest/included]_in_[New/London/United]_[in/but/after]/13)),\n",
       " ('–_[Q2]_;_[Q2]_–', (–_[Q2]_;_[Q2]_–/11)),\n",
       " ('–_[Q2]_;_–', (–_[Q2]_;_–/11)),\n",
       " ('[Q2]_\"_[Q2]_[Q2]_\"', ([Q2]_\"_[Q2]_[Q2]_\"/7)),\n",
       " ('–_[Q2]_;_[Q2]', (–_[Q2]_;_[Ganganelli/Pozzobonelli/Fantuzzi]/6)),\n",
       " ('[Q2]_(_[Q2]_[Q2]', ([-///Ōzora]_(_[now/Milan/indeed]_[//species/from]/6)),\n",
       " ('[Q2]_[_[Q2]_]', ([Q2]_[_[Q2]_]/6)),\n",
       " (\"[Q2]_'_K_'in\", ([Q2]_'_K_'in/5))]"
      ]
     },
     "execution_count": 1488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted({k : v for k, v in m.nodes.items() if k.count('_') > 2 and v.count > 0}.items(), key = lambda x : x[1].count, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the_[Q2]_[Q2]': (the_[game/Little/series]_[of/./,]/89)}"
      ]
     },
     "execution_count": 1459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k : v for k, v in m.nodes.items() if k.startswith('the_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'in': 20,\n",
       "         'also': 59,\n",
       "         'quickly': 20,\n",
       "         'permanently': 20,\n",
       "         'trapped': 20,\n",
       "         'unscathed': 20,\n",
       "         'found': 40,\n",
       "         'popular': 20,\n",
       "         'later': 198,\n",
       "         'erected': 20,\n",
       "         'opened': 20,\n",
       "         'proposed': 20,\n",
       "         'compiled': 20,\n",
       "         'continued': 20,\n",
       "         'fully': 20,\n",
       "         'inspired': 20,\n",
       "         'released': 100,\n",
       "         'used': 100,\n",
       "         'cast': 40,\n",
       "         '@-@': 40,\n",
       "         'sold': 20,\n",
       "         'introduced': 40,\n",
       "         'against': 20,\n",
       "         'largely': 40,\n",
       "         'rebuilt': 20,\n",
       "         'struggling': 20,\n",
       "         'bought': 20,\n",
       "         'appointed': 40,\n",
       "         'replaced': 60,\n",
       "         'followed': 60,\n",
       "         'to': 270,\n",
       "         'revealed': 40,\n",
       "         'awarded': 100,\n",
       "         'completed': 20,\n",
       "         'inducted': 20,\n",
       "         'Villa': 20,\n",
       "         'broken': 20,\n",
       "         'facing': 20,\n",
       "         'mother': 20,\n",
       "         'unknown': 20,\n",
       "         'held': 20,\n",
       "         'submitted': 20,\n",
       "         'sharing': 20,\n",
       "         'attributed': 20,\n",
       "         'reaching': 20,\n",
       "         'brought': 47,\n",
       "         'treated': 20,\n",
       "         'custody': 20,\n",
       "         'responsible': 20,\n",
       "         'approved': 20,\n",
       "         'finally': 20,\n",
       "         'moved': 20,\n",
       "         'sixth': 20,\n",
       "         'delivered': 20,\n",
       "         'established': 20,\n",
       "         'adopted': 20,\n",
       "         'announced': 20,\n",
       "         'offered': 20,\n",
       "         'mostly': 20,\n",
       "         'good': 20,\n",
       "         'one': 100,\n",
       "         'successful': 20,\n",
       "         'becoming': 20,\n",
       "         '1894': 20,\n",
       "         'an': 69,\n",
       "         'moulded': 20,\n",
       "         'only': 40,\n",
       "         'detailed': 20,\n",
       "         'influenced': 20,\n",
       "         'exposed': 20,\n",
       "         '26': 20,\n",
       "         'herself': 20,\n",
       "         'published': 50,\n",
       "         'sustained': 20,\n",
       "         'disrupted': 20,\n",
       "         'made': 20,\n",
       "         'developed': 20,\n",
       "         'fundamental': 20,\n",
       "         'commodity': 20,\n",
       "         'now': 40,\n",
       "         'without': 20,\n",
       "         'growing': 20,\n",
       "         'colleague': 20,\n",
       "         'flattered': 20,\n",
       "         'profoundly': 20,\n",
       "         'rapidly': 20,\n",
       "         'located': 20,\n",
       "         'observed': 20,\n",
       "         'put': 40,\n",
       "         'upgraded': 20,\n",
       "         'estimated': 40,\n",
       "         'discovered': 40,\n",
       "         'named': 80,\n",
       "         'persistent': 20,\n",
       "         'recognized': 20,\n",
       "         '6': 20,\n",
       "         'never': 20,\n",
       "         '16th': 20,\n",
       "         'then': 40,\n",
       "         'encountered': 20,\n",
       "         'still': 40,\n",
       "         'dominated': 20,\n",
       "         'company': 20,\n",
       "         'detached': 20,\n",
       "         'less': 20,\n",
       "         'C': 20,\n",
       "         'attacked': 20,\n",
       "         'immediately': 20,\n",
       "         'subsequently': 20,\n",
       "         'maintained': 20,\n",
       "         'high': 20,\n",
       "         'revised': 20,\n",
       "         'living': 20,\n",
       "         'improving': 20,\n",
       "         'typical': 20,\n",
       "         'increasingly': 20,\n",
       "         'early': 20,\n",
       "         'usually': 20,\n",
       "         'chosen': 40,\n",
       "         'certified': 20,\n",
       "         'nominated': 60,\n",
       "         'completely': 20,\n",
       "         'like': 20,\n",
       "         'head': 20,\n",
       "         'obvious': 20,\n",
       "         ';': 20,\n",
       "         'very': 20,\n",
       "         'song': 20,\n",
       "         'produced': 20,\n",
       "         'meant': 20,\n",
       "         'crying': 20,\n",
       "         'really': 20,\n",
       "         'underway': 20,\n",
       "         'written': 20,\n",
       "         'described': 20,\n",
       "         'first': 40,\n",
       "         'I': 20,\n",
       "         'created': 20,\n",
       "         'sophisticated': 20,\n",
       "         'universally': 20,\n",
       "         'second': 40,\n",
       "         'unparalleled': 20,\n",
       "         'even': 20,\n",
       "         'proven': 20,\n",
       "         'present': 20,\n",
       "         'instead': 20,\n",
       "         'attempting': 20,\n",
       "         'taken': 20,\n",
       "         'irrelevant': 20,\n",
       "         'tried': 20,\n",
       "         'designated': 20,\n",
       "         'advanced': 20,\n",
       "         'approximately': 20,\n",
       "         'abolished': 20,\n",
       "         'complemented': 20,\n",
       "         'familiar': 20,\n",
       "         'defensive': 20,\n",
       "         'led': 30,\n",
       "         'called': 20,\n",
       "         'considered': 20,\n",
       "         'wide': 20,\n",
       "         'transfer': 20,\n",
       "         'recovered': 40,\n",
       "         'penalized': 20,\n",
       "         'intercepted': 20,\n",
       "         'recorded': 20,\n",
       "         'recording': 17,\n",
       "         'People': 16,\n",
       "         ']': 16,\n",
       "         'October': 15,\n",
       "         'major': 15,\n",
       "         'dismayed': 14,\n",
       "         'end': 13,\n",
       "         'certainly': 13,\n",
       "         'colossal': 12,\n",
       "         'obtained': 11,\n",
       "         'liked': 11,\n",
       "         'playing': 9,\n",
       "         'turning': 8,\n",
       "         'counter': 6,\n",
       "         'ruins': 5,\n",
       "         'wounded': 5,\n",
       "         'shipped': 4,\n",
       "         'almost': 3,\n",
       "         'dismasted': 2,\n",
       "         'dead': 1})"
      ]
     },
     "execution_count": 1491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.nodes['[Q2]_was_[Q2]_[Q2]'].slots[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.436686605843415"
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = get_top_n_keys(m.nodes['the_[Q2]'].slots[1], n=6)\n",
    "x = 'York'\n",
    "fdistance_pw(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0956874533221716"
      ]
     },
     "execution_count": 1223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = [0.7505350605337768, 0.5774341990944761, 0.563967412483534, 0.5443518380846117, 0.4899049485976567]\n",
    "0.28/sum(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Little',\n",
       "  'at',\n",
       "  'at',\n",
       "  'at',\n",
       "  'at',\n",
       "  'at',\n",
       "  'after',\n",
       "  'renamed',\n",
       "  'North',\n",
       "  'Big',\n",
       "  'North',\n",
       "  'became',\n",
       "  ',']}"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.nodes['[Q2]_Rock'].slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8918202981106265"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sz = sys.getsizeof(str())\n",
    "print(sz)\n",
    "math.log(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def write_to_file(data_file):\n",
    "    to_file = f\"{data_file}.wtok\"\n",
    "    with open(data_file, errors='ignore') as f, open(to_file, 'w') as tf:\n",
    "        for i, line in tqdm.tqdm(enumerate(f)):\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                #line = line.replace(\"#\", '')\n",
    "                line = by_space.split(line)\n",
    "                #line = \"#\".join(line)\n",
    "                prev = line[0]\n",
    "                new_line = [prev]\n",
    "                \n",
    "                for tok in line[1:]:\n",
    "\n",
    "                    candidate = prev+'_'+tok\n",
    "                    prev_cost, tok_cost = numpy.inf, numpy.inf\n",
    "                    if prev in m.nodes:\n",
    "                        prev_cost = -math.log(m.nodes[prev].count/m.num_tokens)\n",
    "                    if tok in m.nodes:\n",
    "                        tok_cost = -math.log(m.nodes[tok].count/m.num_tokens)\n",
    "\n",
    "                    individual_cost = prev_cost + tok_cost\n",
    "                    mode = 'I'\n",
    "                    best_cost = individual_cost\n",
    "                    head, tail = prev + '_', '_' + tok\n",
    "                    \n",
    "                    \n",
    "                    if head in m.cxns:\n",
    "                        matched = m.cxns[head]\n",
    "                        most_similar = (None, numpy.inf)\n",
    "                            \n",
    "                        for ctail, mat in matched.items():\n",
    "                            slot_pos = (len(mat.form) - 1)\n",
    "                            if slot_pos in mat.slots:\n",
    "                                likely_similar = get_top_n_keys(mat.slots[slot_pos])\n",
    "                            else:\n",
    "                                likely_similar = mat.form[-1]\n",
    "                                        \n",
    "                            similarity = fdistance_pw(tok, likely_similar)\n",
    "                            if similarity < most_similar[1]:\n",
    "                                most_similar = (mat, similarity)\n",
    "                           \n",
    "                        if most_similar[0]:\n",
    "                            mat = most_similar[0]\n",
    "                            slot_pos = (len(mat.form) - 1)\n",
    "                            merge_cost = 0\n",
    "                            slot_cost = 0\n",
    "                            if slot_pos not in mat.slots:\n",
    "                                    pass\n",
    "                            else:\n",
    "                                    # Construction already exists. Need to update the count and avg vector\n",
    "                                cxn_candidate = '_'.join(mat.form)\n",
    "                                cxn_node = m.nodes[cxn_candidate]\n",
    "                                cxn_candidate_cost = -math.log(cxn_node.count / m.num_tokens)\n",
    "                                    #tgt_vector = cxn_node.slotvectors[slot_pos]\n",
    "                        \n",
    "                                cxn_cost = cxn_candidate_cost + most_similar[1] + slot_cost\n",
    "                                if cxn_cost < best_cost:\n",
    "                                    prev = cxn_candidate\n",
    "                                    new_line[-1] = prev\n",
    "                                    mode = 'T_C'\n",
    "                                    best_cost = cxn_cost\n",
    "                    \n",
    "                    if tail in m.cxns:\n",
    "                        matched = m.cxns[tail]\n",
    "                        most_similar = (None, numpy.inf)\n",
    "                            \n",
    "                        for ctail, mat in matched.items():\n",
    "                            slot_pos = 0\n",
    "                            if slot_pos in mat.slots:\n",
    "                                likely_similar = get_top_n_keys(mat.slots[slot_pos])\n",
    "                            else:\n",
    "                                likely_similar = mat.form[-1]\n",
    "                                        \n",
    "                            similarity = fdistance_pw(tok, likely_similar)\n",
    "                            if similarity < most_similar[1]:\n",
    "                                most_similar = (mat, similarity)\n",
    "                           \n",
    "                        if most_similar[0]:\n",
    "                            mat = most_similar[0]\n",
    "                            slot_pos = 0\n",
    "                            merge_cost = 0\n",
    "                            slot_cost = 0\n",
    "                            if slot_pos not in mat.slots:\n",
    "                                    pass\n",
    "                            else:\n",
    "                                    # Construction already exists. Need to update the count and avg vector\n",
    "                                cxn_candidate = '_'.join(mat.form)\n",
    "                                cxn_node = m.nodes[cxn_candidate]\n",
    "                                cxn_candidate_cost = -math.log(cxn_node.count / m.num_tokens)\n",
    "                                    #tgt_vector = cxn_node.slotvectors[slot_pos]\n",
    "                        \n",
    "                                cxn_cost = cxn_candidate_cost + most_similar[1]\n",
    "                                if cxn_cost < best_cost:\n",
    "                                    prev = cxn_candidate\n",
    "                                    new_line[-1] = prev\n",
    "                                    mode = 'C_T'\n",
    "                                    best_cost = cxn_cost\n",
    "                                \n",
    "                    if candidate in m.nodes:\n",
    "                        candidate_cost = -math.log(m.nodes[candidate].count/m.num_tokens)\n",
    "                        if candidate_cost < best_cost:\n",
    "                            prev = candidate\n",
    "                            new_line[-1] = prev\n",
    "                            mode = 'T_T'\n",
    "                        else:\n",
    "                            prev = tok\n",
    "                            new_line.append(tok)\n",
    "                    elif mode == 'I':\n",
    "                            prev = tok\n",
    "                            new_line.append(tok)\n",
    "                    \n",
    "                #tf.write(' '.join(new_line) + '\\n')\n",
    "                print(line)\n",
    "                print(' '.join(new_line), end=' ')\n",
    "                print(\"\\n\"+\"-\"*20)\n",
    "\n",
    "            if i > 10:\n",
    "                break\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 57.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=', 'Valkyria', 'Chronicles', 'III', '=']\n",
      "= Valkyria_[Q2] [Q2]_= \n",
      "--------------------\n",
      "['Senjō', 'no', 'Valkyria', '3', ':', '<unk>', 'Chronicles', '(', 'Japanese', ':', '戦場のヴァルキュリア3', ',', 'lit', '.', 'Valkyria', 'of', 'the', 'Battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'Valkyria', 'Chronicles', 'III', 'outside', 'Japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'Sega', 'and', 'Media.Vision', 'for', 'the', 'PlayStation', 'Portable', '.', 'Released', 'in', 'January', '2011', 'in', 'Japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'Valkyria', 'series', '.', '<unk>', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'Nameless', '\"', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'Gallia', 'during', 'the', 'Second', 'Europan', 'War', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'Imperial', 'unit', '\"', '<unk>', 'Raven', '\"', '.']\n",
      "[Q2]_no Valkyria_[Q2] : <unk>_[Q2] ( Japanese [Q2]_, [Q2]_. [Q2]_, commonly [Q3]_to_[Q2] Valkyria_[Q2] III outside [Q2]_a [Q2]_role @-@ playing [Q2]_game [Q3]_by Sega and Media.Vision for_[Q2]_[Q2] [Q2]_._[Q2] in_[Q2]_[Q2] [Q2]_, [Q2]_is_[Q2] [Q2]_game [Q2]_the [Q2]_series_[Q2] <unk>_[Q2] [Q2]_of tactical and real [Q2]_time gameplay [Q2]_its [Q2]_the_[Q2] runs [Q2]_game and [Q2]_the_[Q2] Nameless [Q2]_a penal military unit [Q2]_of Gallia during_[Q2] Second Europan War who_[Q2]_[Q2] black operations and [Q2]_the_[Q2] unit \" <unk>_[Q2] [Q2]_. \n",
      "--------------------\n",
      "['The', 'game', 'began', 'development', 'in', '2010', ',', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'Valkyria', 'Chronicles', 'II', '.', 'While', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', ',', 'it', 'also', 'underwent', 'multiple', 'adjustments', ',', 'such', 'as', 'making', 'the', 'game', 'more', '<unk>', 'for', 'series', 'newcomers', '.', 'Character', 'designer', '<unk>', 'Honjou', 'and', 'composer', 'Hitoshi', 'Sakimoto', 'both', 'returned', 'from', 'previous', 'entries', ',', 'along', 'with', 'Valkyria', 'Chronicles', 'II', 'director', 'Takeshi', 'Ozawa', '.', 'A', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', '.', 'The', 'game', \"'s\", 'opening', 'theme', 'was', 'sung', 'by', 'May', \"'n\", '.']\n",
      "[Q2]_game began development [Q2]_, [Q2]_a large [Q2]_the_[Q2] [Q4]_on Valkyria_[Q2] [Q2]_._[Q2] it [Q2]_the_[Q2] [Q2]_, [Q2]_also underwent multiple [Q2]_, such [Q2]_more [Q2]_._[Q2] designer <unk> Honjou and composer Hitoshi Sakimoto [Q2]_from_[Q2] [Q2]_, [Q3]_with Valkyria_[Q2] II director Takeshi [Q2]_._[Q2] [Q2]_of writers [Q2]_game [Q3]_was [Q2]_May [Q2]_. \n",
      "--------------------\n",
      "['It', 'met', 'with', 'positive', 'sales', 'in', 'Japan', ',', 'and', 'was', 'praised', 'by', 'both', 'Japanese', 'and', 'western', 'critics', '.', 'After', 'release', ',', 'it', 'received', 'downloadable', 'content', ',', 'along', 'with', 'an', 'expanded', 'edition', 'in', 'November', 'of', 'that', 'year', '.', 'It', 'was', 'also', 'adapted', 'into', 'manga', 'and', 'an', 'original', 'video', 'animation', 'series', '.', 'Due', 'to', 'low', 'sales', 'of', 'Valkyria', 'Chronicles', 'II', ',', 'Valkyria', 'Chronicles', 'III', 'was', 'not', 'localized', ',', 'but', 'a', 'fan', 'translation', 'compatible', 'with', 'the', 'game', \"'s\", 'expanded', 'edition', 'was', 'released', 'in', '2014', '.', 'Media.Vision', 'would', 'return', 'to', 'the', 'franchise', 'with', 'the', 'development', 'of', 'Valkyria', ':', 'Azure', 'Revolution', 'for', 'the', 'PlayStation', '4', '.']\n",
      "It [Q3]_with positive sales [Q2]_, [Q3]_was [Q3]_by both_[Q2] and western [Q2]_._[Q2] [Q2]_, it received [Q2]_, [Q2]_an expanded edition [Q2]_into manga [Q2]_an original video [Q2]_series_[Q2] [Q3]_to_[Q2] [Q2]_of Valkyria_[Q2] [Q2]_, Valkyria_[Q2] [Q2]_not [Q2]_, [Q2]_a fan translation [Q2]_game [Q2]_released in_[Q2]_[Q2] Media.Vision [Q2]_of Valkyria_[Q2] Azure Revolution for_[Q2]_[Q2] [Q2]_. \n",
      "--------------------\n",
      "['=', '=', 'Gameplay', '=', '=']\n",
      "[Q2]_= [Q2]_= \n",
      "--------------------\n",
      "['As', 'with', 'previous', '<unk>', 'Chronicles', 'games', ',', 'Valkyria', 'Chronicles', 'III', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'game', 'where', 'players', 'take', 'control', 'of', 'a', 'military', 'unit', 'and', 'take', 'part', 'in', 'missions', 'against', 'enemy', 'forces', '.', 'Stories', 'are', 'told', 'through', 'comic', 'book', '@-@', 'like', 'panels', 'with', 'animated', 'character', 'portraits', ',', 'with', 'characters', 'speaking', 'partially', 'through', 'voiced', 'speech', 'bubbles', 'and', 'partially', 'through', '<unk>', 'text', '.', 'The', 'player', 'progresses', 'through', 'a', 'series', 'of', 'linear', 'missions', ',', 'gradually', 'unlocked', 'as', 'maps', 'that', 'can', 'be', 'freely', '<unk>', 'through', 'and', 'replayed', 'as', 'they', 'are', 'unlocked', '.', 'The', 'route', 'to', 'each', 'story', 'location', 'on', 'the', 'map', 'varies', 'depending', 'on', 'an', 'individual', 'player', \"'s\", 'approach', ':', 'when', 'one', 'option', 'is', 'selected', ',', 'the', 'other', 'is', 'sealed', 'off', 'to', 'the', 'player', '.', 'Outside', 'missions', ',', 'the', 'player', 'characters', 'rest', 'in', 'a', 'camp', ',', 'where', 'units', 'can', 'be', 'customized', 'and', 'character', 'growth', 'occurs', '.', 'Alongside', 'the', 'main', 'story', 'missions', 'are', 'character', '@-@', 'specific', 'sub', 'missions', 'relating', 'to', 'different', 'squad', 'members', '.', 'After', 'the', 'game', \"'s\", 'completion', ',', 'additional', 'episodes', 'are', 'unlocked', ',', 'some', 'of', 'them', 'having', 'a', 'higher', 'difficulty', 'than', 'those', 'found', 'in', 'the', 'rest', 'of', 'the', 'game', '.', 'There', 'are', 'also', 'love', 'simulation', 'elements', 'related', 'to', 'the', 'game', \"'s\", 'two', 'main', '<unk>', ',', 'although', 'they', 'take', 'a', 'very', 'minor', 'role', '.']\n",
      "[Q3]_with previous <unk>_[Q2] [Q2]_, Valkyria_[Q2] [Q2]_a [Q2]_role @-@ [Q2]_game where players [Q2]_a military unit and [Q2]_part in_[Q2]_[Q2] enemy [Q2]_._[Q2] are_[Q2] through comic_[Q2] [Q2]_like [Q3]_with animated character [Q3]_with characters speaking partially through voiced speech bubbles and partially through [Q2]_._[Q2] player progresses [Q2]_series_[Q2] linear [Q2]_, gradually unlocked [Q2]_be freely <unk>_[Q2] and replayed as_[Q2]_[Q2] [Q3]_to_[Q2] story [Q2]_the_[Q2] varies [Q2]_an individual player 's_[Q2]_[Q2] [Q2]_._[Q2] [Q2]_the_[Q2] characters rest [Q2]_a [Q2]_, where [Q2]_be customized and character growth [Q2]_. [Q2]_the_[Q2] story missions are_[Q2] @-@ specific sub missions [Q3]_to different squad [Q2]_game [Q2]_, additional episodes [Q2]_, [Q2]_them [Q2]_a higher [Q2]_than those [Q2]_._[Q2] [Q2]_also love simulation elements [Q2]_game 's_[Q2]_[Q2] [Q2]_, although [Q2]_a very [Q2]_. \n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'game', \"'s\", 'battle', 'system', ',', 'the', '<unk>', 'system', ',', 'is', 'carried', 'over', 'directly', 'from', '<unk>', 'Chronicles', '.', 'During', 'missions', ',', 'players', 'select', 'each', 'unit', 'using', 'a', 'top', '@-@', 'down', 'perspective', 'of', 'the', 'battlefield', 'map', ':', 'once', 'a', 'character', 'is', 'selected', ',', 'the', 'player', 'moves', 'the', 'character', 'around', 'the', 'battlefield', 'in', 'third', '@-@', 'person', '.', 'A', 'character', 'can', 'only', 'act', 'once', 'per', '@-@', 'turn', ',', 'but', 'characters', 'can', 'be', 'granted', 'multiple', 'turns', 'at', 'the', 'expense', 'of', 'other', 'characters', \"'\", 'turns', '.', 'Each', 'character', 'has', 'a', 'field', 'and', 'distance', 'of', 'movement', 'limited', 'by', 'their', 'Action', '<unk>', '.', 'Up', 'to', 'nine', 'characters', 'can', 'be', 'assigned', 'to', 'a', 'single', 'mission', '.', 'During', 'gameplay', ',', 'characters', 'will', 'call', 'out', 'if', 'something', 'happens', 'to', 'them', ',', 'such', 'as', 'their', 'health', 'points', '(', 'HP', ')', 'getting', 'low', 'or', 'being', 'knocked', 'out', 'by', 'enemy', 'attacks', '.', 'Each', 'character', 'has', 'specific', '\"', 'Potentials', '\"', ',', 'skills', 'unique', 'to', 'each', 'character', '.', 'They', 'are', 'divided', 'into', '\"', 'Personal', 'Potential', '\"', ',', 'which', 'are', 'innate', 'skills', 'that', 'remain', 'unaltered', 'unless', 'otherwise', 'dictated', 'by', 'the', 'story', 'and', 'can', 'either', 'help', 'or', 'impede', 'a', 'character', ',', 'and', '\"', 'Battle', 'Potentials', '\"', ',', 'which', 'are', 'grown', 'throughout', 'the', 'game', 'and', 'always', 'grant', '<unk>', 'to', 'a', 'character', '.', 'To', 'learn', 'Battle', 'Potentials', ',', 'each', 'character', 'has', 'a', 'unique', '\"', 'Masters', 'Table', '\"', ',', 'a', 'grid', '@-@', 'based', 'skill', 'table', 'that', 'can', 'be', 'used', 'to', 'acquire', 'and', 'link', 'different', 'skills', '.', 'Characters', 'also', 'have', 'Special', '<unk>', 'that', 'grant', 'them', 'temporary', '<unk>', 'on', 'the', 'battlefield', ':', 'Kurt', 'can', 'activate', '\"', 'Direct', 'Command', '\"', 'and', 'move', 'around', 'the', 'battlefield', 'without', '<unk>', 'his', 'Action', 'Point', 'gauge', ',', 'the', 'character', '<unk>', 'can', 'shift', 'into', 'her', '\"', 'Valkyria', 'Form', '\"', 'and', 'become', '<unk>', ',', 'while', 'Imca', 'can', 'target', 'multiple', 'enemy', 'units', 'with', 'her', 'heavy', 'weapon', '.']\n",
      "[Q2]_game [Q2]_the [Q2]_over [Q2]_from [Q2]_._[Q2] [Q2]_, players select each unit [Q2]_top [Q2]_the_[Q2] map [Q2]_a [Q2]_the_[Q2] [Q2]_the_[Q2] [Q2]_the_[Q2] in_[Q2]_[Q2] [Q2]_._[Q2] [Q2]_only act once_[Q2] @-@ [Q2]_, [Q2]_be granted multiple turns [Q2]_other characters [Q2]_._[Q2] [Q2]_field and [Q2]_of movement [Q2]_their Action <unk>_[Q2] [Q3]_to_[Q2] [Q2]_be [Q2]_a [Q2]_._[Q2] [Q2]_, characters will [Q2]_if something [Q2]_, such as_[Q2]_[Q2] points ( HP )_[Q3] low or_[Q2] [Q3]_by enemy [Q2]_._[Q2] [Q2]_has specific \" Potentials [Q2]_, skills [Q3]_to_[Q2] [Q2]_._[Q2] [Q2]_into \"_[Q2]_[Q2] [Q2]_, which are_[Q2] [Q2]_that remain unaltered unless otherwise [Q2]_the_[Q2] [Q2]_can either help or [Q2]_a [Q2]_, and \"_[Q2] Potentials [Q2]_, which are_[Q2] [Q2]_game and always grant [Q2]_a [Q2]_._[Q2] learn Battle [Q2]_, each [Q2]_a unique \"_[Q2]_[Q2] [Q2]_a grid @-@ based skill [Q2]_be [Q3]_to_[Q2] and link different [Q2]_have Special <unk>_[Q2] [Q2]_them temporary [Q2]_the_[Q2] : [Q2]_can activate \"_[Q2]_[Q2] \"_[Q2]_[Q2] [Q2]_the_[Q2] without <unk>_[Q2] Action Point [Q2]_the_[Q2] <unk>_[Q2] [Q2]_her \" Valkyria_[Q2] \"_[Q2]_[Q2] [Q2]_, while [Q2]_can target multiple enemy [Q2]_her [Q2]_. \n",
      "--------------------\n",
      "['Troops', 'are', 'divided', 'into', 'five', 'classes', ':', 'Scouts', ',', '<unk>', ',', 'Engineers', ',', '<unk>', 'and', 'Armored', 'Soldier', '.', '<unk>', 'can', 'switch', 'classes', 'by', 'changing', 'their', 'assigned', 'weapon', '.', 'Changing', 'class', 'does', 'not', 'greatly', 'affect', 'the', 'stats', 'gained', 'while', 'in', 'a', 'previous', 'class', '.', 'With', 'victory', 'in', 'battle', ',', 'experience', 'points', 'are', 'awarded', 'to', 'the', 'squad', ',', 'which', 'are', 'distributed', 'into', 'five', 'different', 'attributes', 'shared', 'by', 'the', 'entire', 'squad', ',', 'a', 'feature', 'differing', 'from', 'early', 'games', \"'\", 'method', 'of', 'distributing', 'to', 'different', 'unit', 'types', '.']\n",
      "Troops [Q2]_into five_[Q2] [Q2]_, [Q2]_, [Q2]_, <unk>_[Q2] Armored [Q2]_can switch [Q3]_by [Q2]_their assigned [Q2]_._[Q2] class [Q2]_not greatly [Q2]_the_[Q2] gained [Q2]_a previous [Q2]_._[Q2] victory [Q2]_, experience points [Q2]_, which [Q2]_into five_[Q2] attributes [Q2]_the_[Q2] [Q2]_a feature [Q2]_from_[Q2] games [Q2]_of [Q3]_to different unit [Q2]_. \n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_to_file(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.605170185988092"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(VECDIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['b'] = 2\n",
    "x['a'] = 1\n",
    "x['c'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'b': 2, 'c': 1})"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('a', 1), ('c', 1)]"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
